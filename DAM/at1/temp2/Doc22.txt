Graph theory area mathematics analyses relationships pairs objects. Typically graphs consist nodes (points representing objects) edges (lines depicting relationships objects). As one might imagine, graphs extremely useful visualizing relationships objects. In post, I provide detailed introduction network graphs using R, premier open source tool statistics package calculations excellent Gephi software visualization. The article organised follows: I begin defining problem spend time developing concepts used constructing graph Following , I data preparation R finally build network graph using Gephi. The problem In introductory article cluster analysis, I provided -depth introduction couple algorithms can used categorise documents automatically. Although techniques useful, provide feel relationships different documents collection interest. In present piece I show network graphs can used visualise similarity-based relationships within corpus. Document similarity There many ways quantify similarity documents. A popular method use notion distance documents. The basic idea simple: documents many words common "closer" share fewer words. The problem distance, however, can skewed word count: documents unusually high word count will show outliers even though may similar ( terms words used) documents corpus. For reason, will use another related measure similarity suffer problem   minute. Representing documents mathematically As I explained article cluster analysis, document can represented point conceptual space dimensionality equal number distinct words collection documents. I revisit build explanation . Say one simple document consisting words "five plus six", one can represent mathematically 3 dimensional space individual words represented three axis (See Figure 1). Here word coordinate axis ( dimension). Now, one connects point representing document (point A figure) origin word-space, one vector, case directed line connecting point question origin. Specifically, point A can represented coordinates (1, 1, 1) space. This nice quantitative representation fact words five, plus one appear document exactly . Note, however, assumed order words matter. This reasonable assumption cases, always . Figure 1 Figure 1 As another example consider document, B, consists two words: "five plus" (see Fig 2). Clearly document shares similarity document identical. Indeed, becomes evident note document ( point) B simply point $latex(1, 1, 0)$ space, tells us two coordinates (words/frequencies) common document ( point) A. Figure 2 Figure 2 To sure, realistic collection documents large number distinct words, work high dimensional space. Nevertheless, principle holds: every document corpus can represented vector consisting directed line origin point document corresponds. Cosine similarity Now easy see two documents identical correspond point. In words, vectors coincide. On hand, completely dissimilar ( words common), vectors will right angles . What need, therefore, quantity varies 0 1 depending whether two documents (vectors) dissimilar( right angles ) similar (coincide, parallel ). Now ultra-cool thing, high school maths class, know trigonometric ratio exactly property   cosine! What's even cooler cosine angle two vectors simply dot product two vectors, sum products individual elements vector, divided product lengths two vectors. In three dimensions can expressed mathematically : \cos(\theta)= \displaystyle \frac{x_1 x_2+y_1 y_2+z_1 z_2}{\sqrt{x_1^2+y_1^2+z_1^2}\sqrt{x_2^2+y_2^2+z_2^2}}...(1) two vectors (x_{1},y_{1},z_{1}) (x_{2},y_{2},z_{2}) , \theta angle two vectors (see Fig 2). The upshot cosine angle vector representation two documents reasonable measure similarity . This quantity, sometimes referred cosine similarity, take similarity measure rest article. The adjacency matrix If collection N documents, can calculate similarity every pair documents A B previous section. This give us set N^2 numbers 0 1, can conveniently represented matrix. This sometimes called adjacency matrix. Beware, though, term many different meanings math literature. I use sense specified . Since every document identical , diagonal elements matrix will 1. These similarities trivial ( know every document identical !) set diagonal elements zero. Another important practical point visualizing every relationship going make messy graph. There N(N-1) edges graph, make impossible make sense handful documents. For reason, normal practice choose cutoff value similarity set zero. Building adjacency matrix using R We now enough background get main point article   visualizing relationships documents. The first step build adjacency matrix. In order , build document term matrix (DTM) collection documents, process I dealt length introductory pieces text mining topic modeling. In fact, steps actually identical detailed second piece. I will therefore avoid lengthy explanations . However, I've listed code brief comments ( interested trying , document corpus can downloaded pdf listing R code can obtained .) OK, code listing: #load text mining library library(tm) #set working directory (modify path needed) setwd("C:\\Users\\Kailash\\Documents\\TextMining") #load files corpus #get listing .txt files directory filenames <- list.files(getwd(),pattern="*.txt") #read files character vector files <- lapply(filenames,readLines) #create corpus vector docs <- Corpus(VectorSource(files)) #inspect particular document corpus writeLines(.character(docs[[30]])) #start preprocessing #Transform lower case docs <-tm_map(docs,content_transformer(tolower)) #remove potentially problematic symbols toSpace <- content_transformer(function(x, pattern) { return (gsub(pattern, " ", x))}) docs <- tm_map(docs, toSpace, "-") docs <- tm_map(docs, toSpace, "'") docs <- tm_map(docs, toSpace, "‘") docs <- tm_map(docs, toSpace, "•") docs <- tm_map(docs, toSpace, """) docs <- tm_map(docs, toSpace, """) #remove punctuation docs <- tm_map(docs, removePunctuation) #Strip digits docs <- tm_map(docs, removeNumbers) #remove stopwords docs <- tm_map(docs, removeWords, stopwords("english")) #remove whitespace docs <- tm_map(docs, stripWhitespace) #Good practice check every now writeLines(.character(docs[[30]])) #Stem document docs <- tm_map(docs,stemDocument) #fix 1) differences us aussie english 2) general errors docs <- tm_map(docs, content_transformer(gsub), pattern = "organiz", replacement = "organ") docs <- tm_map(docs, content_transformer(gsub), pattern = "organis", replacement = "organ") docs <- tm_map(docs, content_transformer(gsub), pattern = "andgovern", replacement = "govern") docs <- tm_map(docs, content_transformer(gsub), pattern = "inenterpris", replacement = "enterpris") docs <- tm_map(docs, content_transformer(gsub), pattern = "team-", replacement = "team") #define eliminate custom stopwords myStopwords <- c("can", "say","one","way","use", "also","howev","tell","will", "much","need","take","tend","even", "like","particular","rather","said", "get","well","make","ask","come","end", "first","two","help","often","may", "might","see","someth","thing","point", "post","look","right","now","think","‘ve ", "‘re ","anoth","put","set","new","good", "want","sure","kind","larg","yes,","day","etc", "quit","sinc","attempt","lack","seen","awar", "littl","ever","moreov","though","found","abl", "enough","far","earli","away","achiev","draw", "last","never","brief","bit","entir","brief", "great","lot") docs <- tm_map(docs, removeWords, myStopwords) #inspect document check writeLines(.character(docs[[30]])) #Create document-term matrix dtm <- DocumentTermMatrix(docs) The rows DTM document vectors akin vector representations documents A B discussed earlier. The DTM therefore contains information need calculate cosine similarity every pair documents corpus (via equation 1). The R code implements , taking care preliminaries. #convert dtm matrix m<-.matrix(dtm) #write csv file write.csv(m,file="dtmEight2Late.csv") #Map filenames matrix row numbers # numbers will used reference #files network graph filekey <- cbind(rownames(m),filenames) write.csv(filekey,"filekey.csv") #compute cosine similarity document vectors #converting distance matrix sets diagonal elements 0 cosineSim <- function(x){ .dist(x%*%t(x)/(sqrt(rowSums(x^2) %*% t(rowSums(x^2))))) } cs <- cosineSim(m) write.csv(.matrix(cs),file="csEight2Late.csv") #adjacency matrix: set entries certain threshold 0. #We choose half magnitude largest element matrix # cutoff. This arbitrary choice cs[cs < max(cs)/2] <- 0 cs <- round(cs,3) write.csv(.matrix(cs),file="AdjacencyMatrix.csv") A lines need brief explanation: First , although DTM matrix, internally stored special form suitable sparse matrices. We therefore explicitly convert proper matrix using calculate similarity. Second, names I given documents way long use labels network diagram. I therefore mapped document names row numbers use network graph later. The mapping back original document names stored filekey.csv. For future reference, mapping shown Table 1 . File number Name 1 BeyondEntitiesAndRelationships.txt 2 bigdata.txt 3 ConditionsOverCauses.txt 4 EmergentDesignInEnterpriseIT.txt 5 FromInformationToKnowledge.txt 6 FromTheCoalface.txt 7 HeraclitusAndParmenides.txt 8 IroniesOfEnterpriseIT.txt 9 MakingSenseOfOrganizationalChange.txt 10 MakingSenseOfSensemaking.txt 11 ObjectivityAndTheEthicalDimensionOfDecisionMaking.txt 12 OnTheInherentAmbiguitiesOfManagingProjects.txt 13 OrganisationalSurprise.txt 14 ProfessionalsOrPoliticians.txt 15 RitualsInInformationSystemDesign.txt 16 RoutinesAndReality.txt 17 ScapegoatsAndSystems.txt 18 SherlockHolmesFailedProjects.txt 19 sherlockHolmesMgmtFetis.txt 20 SixHeresiesForBI.txt 21 SixHeresiesForEnterpriseArchitecture.txt 22 TheArchitectAndTheApparition.txt 23 TheCloudAndTheGrass.txt 24 TheConsultantsDilemma.txt 25 TheDangerWithin.txt 26 TheDilemmasOfEnterpriseIT.txt 27 TheEssenceOfEntrepreneurship.txt 28 ThreeTypesOfUncertainty.txt 29 TOGAFOrNotTOGAF.txt 30 UnderstandingFlexibility.txt Table 1: File mappings Finally, distance function (.dist) cosine similarity function sets diagonal elements zero distance document zero  just complicated way saying document identical <U+653C><U+3E64><U+613C><U+3E30><U+623C><U+3E64><U+653C><U+3E64><U+623C><U+3E39><U+383C><U+3E32> The last three lines code simply implement cutoff I mentioned previous section. The comments explain details I need say .   finally brings us Gephi. Visualizing document similarity using Gephi Gephi open source, Java based network analysis visualisation tool. Before going , may want download install . While may also want download excellent quick start tutorial. Go , I'll wait   To begin , little formatting quirk need deal . Gephi expects separators csv files semicolons (;) . So, first step open adjacency matrix created previous section (AdjacencyMatrix.csv) text editor replace commas semicolons. Once done , fire Gephi, go File > Open, navigate Adjacency matrix stored load file. If loads successfully, see feedback panel shown Figure 3. By default Gephi creates directed graph (.e one edges arrows pointing one node another). Change undirected click OK. Figure 3: Gephi import feedback Figure 3: Gephi import feedback Once done, click overview (top left screen). You end something like Figure 4. Figure 4: Initial overview loading adjacency matrix Figure 4: Initial overview loading adjacency matrix Gephi sketched initial network diagram depicts relationships documents  needs bit work make look nicer informative. The quickstart tutorial mentioned earlier describes various features can used manipulate prettify graph. In remainder section, I list I found useful. Gephi offers many . Do explore, much I can cover introductory post. First basics. You can: Zoom pan using mouse wheel right button. Adjust edge thicknesses using slider next text formatting options bottom left main panel. Re-center graph via magnifying glass icon left display panel (just size adjuster). Toggle node labels / clicking grey T symbol bottom left panel. Figure 5 shows state diagram labels added edge thickness adjusted (note graph may vary appearance). Figure 5: graph node labels adjusted edge thicknesses Figure 5: graph node labels adjusted edge thicknesses The default layout graph ugly hard interpret. Let's work fixing . To , go layout panel left. Experiment different layouts see . After messing around, I found Fruchtermann-Reingold Force Atlas options good graph. In end I used Force Atlas Repulsion Strength 2000 ( default 200) Attraction Strength 1 ( default 10). I also adjusted figure size node label font size graph panel center. The result shown Figure 6. Figure 6: Graph using Force Atlas layout Figure 6: Graph using Force Atlas layout This much better. For example, now evident document 9 connected one ( table 9 tells us transcript conversation Neil Preston organisational change). It nice colour code edges/nodes size nodes degree connectivity. This can done via ranking panel layout area just working. In Nodes tab select Degree rank parameter ( degree connectivity node) hit apply. Select preferred colours via small icon just colour slider. Use colour slider adjust degree connectivity colour transitions occur. Do edges, selecting weight rank parameter( degree similarity two douments connected edge). With bit playing around, I got graph shown screenshot (Figure 7). Figure 7: Connectivity-based colouring edges nodes. Figure 5: Connectivity-based colouring edges nodes. If want see numerical values rankings, hit results list icon bottom left ranking panel. You can see numerical ranking values nodes edges shown Figures 8 9. Figure 8: Node ranking Figure 8: Node ranking (see left figure) Figure 9: Edge ranking Figure 9: Edge ranking It easy see figure documents 21 29 similar terms cosine ranking. This makes sense, pieces I ranted current state enterprise architecture   first article EA general TOGAF framework. If quick skim , see fair bit common. Finally, nice adjust node size reflect connectedness associated document. You can via "gem" symbol top right ranking panel. Select appropriate min max sizes (I chose defaults) hit apply. The node size now reflective connectivity node   .e. number documents cosine similar varying degrees. The thickness edges reflect degree similarity. See Figure 10. Figure 10: Node sizes reflecting connectedness Figure 10: Node sizes reflecting connectedness Now looks good enough export. To , hit preview tab main panel make following adjustments default settings: Under Node Labels: 1. Check Show Labels 2. Uncheck proportional size 3. Adjust font required size Under Edges: 1. Change thickness 10 2. Check rescale weight Hit refresh making adjustments. You get something like Fig 11. Figure 11: Export preview Figure 11: Export preview All remains now deed: hit export SVG/PDF/PNG export diagram. My output displayed Figure 12. It clearly shows relationships different documents (nodes) corpus. The nodes highest connectivity indicated via node size colour (purple high, green low) strength similarity indicated edge thickness. Figure 12: Gephi network graph Figure 12: Gephi network graph document corpus   brings us end journey. Wrapping The techniques text analysis enable us quantify relationships documents. Document similarity one relationship. Numerical measures good, comprehensibility can enhanced meaningful visualisations. Indeed, although stated objective article provide introduction creating network graphs using Gephi R ( I hope I've succeeded ), secondary aim show document similarity can quantified visualised. I sincerely hope found discussion interesting useful. Many thanks reading! As always, feedback greatly appreciated.
